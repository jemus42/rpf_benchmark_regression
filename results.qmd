---
title: "RPF Regression Benchmark Results"
author: "Lukas"
date: now
date-format: "YYYY-MM-DD HH:mm z"
date-modified: last-modified
format: 
  html:
    code-fold: true
    fig-align: center
    toc: true
  pdf: 
    documentclass: article
    fig-align: center
    toc: true
    date: now
    keep-tex: true
    knitr: 
      opts_chunk: 
        echo: false
        fig.pos: H
    include-in-header: 
      - \usepackage{float}
editor_options: 
  chunk_output_type: console
---

```{r setup}
#| message: false
#| warning: false
library(ggplot2)
library(ragg)
library(mlr3)
#library(mlr3batchmark)
#library(mlr3viz)
#library(mlr3tuning)
library(data.table)
library(dplyr)
library(kableExtra)

# Load task metadata
task_meta <- readRDS("task_meta.rds")

task_meta <- task_meta |>
  arrange(dim_rank) |>
  mutate(
    task_label = glue::glue("{task_id} ({n} x {p})"),
    task_label = factor(task_label, levels = task_label, ordered = TRUE),
    task_id = factor(task_id, levels = task_id, ordered = TRUE)
  )

# benchmark results + cleanup
# bmr   <- readRDS(fs::path(conf$result_path, "bmr", ext = "rds"))
aggr   <- readRDS(fs::path(conf$result_path, "aggr",   ext = "rds"))
scores <- readRDS(fs::path(conf$result_path, "scores", ext = "rds"))

scores <- task_meta[scores, on = c("task_id")]

# Define learner colors for somewhat identifiable plots
learner_cols <- c(
  "rpf" = "#F73098",
  "xgb" = "#3BA99C",
  "rpf_fixdepth" = "#CA1694",
  "xgb_fixdepth" = "#256A62",
  "ranger" = "#2171B5",
  "featureless" = "#484848"
)
learner_order <- names(learner_cols)
learner_label <- function(x) {
  c("rpf" = "RPF", "xgb" = "XGBoost", "rpf_fixdepth" = "RPF (max_int.=2)", "xgb_fixdepth" = "XGBoost (max_depth=2)", "ranger" = "ranger", "featureless" = "Featureless")[x]
}

# aggr[, learner_label := learner_label(learner_id)]
# scores[, learner_label := learner_label(learner_id)]
aggr[, learner_id := factor(learner_id, levels = rev(learner_order))]
scores[, learner_id := factor(learner_id, levels = rev(learner_order))]

set.seed(3) # Only for jitterdodge consistency
```

## Benchmark Setup

- Inner resampling: 2x3-fold repeated CV
- Outer resampling: 10-fold CV using the same resampling folds as [the CTR-23 paper](https://openreview.net/pdf?id=HebAOoMm94). Some tasks use multiple repetitions.
- Bayesian optimization with 200 evaluations
- A runtime limit of 7 days for each outer resampling fold (including tuning)

### Hyperparameter Search Spaces

### `rpf`/`rpf_fixmax`

- `ntrees` := 50
- `max_interaction` in [1, 20]
    - Via `max_interaction_ratio` in [0, 1] and `max_interaction_limit` := 20
    - for `rpf_fixmax`: `max_interaction` := 2
- `splits` in [10, 100]
- `splits_try` in [1, 20]
- `t_try` in [0.1, 1]

### `ranger`

- `num.trees` := 500
- `mtry.ratio` in [0.1, 1]
- `min.node.size` in [1, 50]
- `sample.fracton` in [0.1, 1]

### `xgboost`/`xgboost_fixdepth`

- Preprocessing of categorical features using treatment encoding
- `max_depth` in [1, 20]
    - for `xgb_fixdepth`: `max_depth` := 2
- `subsample` in [0.1, 1]
- `colsample_bytree` in [0.1, 1]
- `eta` in [0, 1] (log scale)
- `nrounds` tuned internally via early stopping with 50 rounds of patience


## Regression Benchmark Results

- Tuning on MSE
- Evaluation on RMSE, MAE, [RRSE](https://mlr3measures.mlr-org.com/reference/rrse.html)

### Tasks

[OpenML CTR-23](https://www.openml.org/search?type=study&study_type=task&sort=tasks_included&id=353) tasks with:

- No missing values
- $n \cdot p \leq 10^6$
- No features of type `logical` or `character`

```{r tasks}
task_meta |>
  select(task_id, n, p, dim) |>
  arrange(dim) |>
  kbl(
    caption = "Selected OpenML CTR-23 tasks, arranged by dimensionality",
    col.names = c("Task", "n", "p", "nÂ·p"),
    booktabs = TRUE
  ) |>
  kable_styling()
```

### Aggregated Results

```{r}

plot_aggr <- function(xdf, 
                      measures = c("rmse", "mae", "rrse"),
                      include_featless = TRUE, logscale = FALSE, ncol = 2) {
  
  xdf <- xdf |>
    tidyr::pivot_longer(
      cols = any_of(measures),
      names_to = "measure",
      values_to = "score"
    )

  if (!include_featless) {
    xdf <- xdf |>
      filter(learner_id != "featureless")
  }

  p <- xdf |>
    filter(.data$measure %in% .env$measures) |>
    ggplot(aes(y = learner_id, x = score, fill = learner_id)) +
    facet_wrap(vars(measure), ncol = ncol, scales = "free", labeller = \(x) lapply(x, toupper)) +
    geom_boxplot(alpha = .5) +
    geom_point(
      position = position_jitterdodge(dodge.width = .25),
      shape = 21
    ) +
    scale_y_discrete(labels = learner_label) +
    scale_fill_manual(values = learner_cols, guide = "none") +
    labs(
      #title = "Aggregated scores over all tasks",
      x = NULL, y = NULL
    ) +
    theme_minimal(base_size = 14) +
    theme(
      plot.title.position = "plot"
    )
  
  if (logscale) {
    p <- p + scale_x_continuous(labels = scales::label_comma())
  } else {
    p <- p + scale_x_log10(labels = scales::label_comma())
  }
  p
}
```


#### Boxplot

```{r aggregated}
#| fig-width: 12
#| fig-height: 7
#| fig-align: center
#| column: screen-inset-shaded

plot_aggr(aggr, include_featless = TRUE, logscale = FALSE, ncol = 2)

```

Without featureless learner

```{r aggregated-no-featless}
#| fig-width: 12
#| fig-height: 7
#| fig-align: center
#| column: screen-inset-shaded

plot_aggr(aggr, include_featless = FALSE, logscale = FALSE, ncol = 2)

```

#### Table

```{r aggregated-table}
# column: screen-inset-shaded
aggr |>
  tidyr::pivot_longer(
    cols = any_of(c("rmse", "mae", "rrse")),
    names_to = "measure", names_transform = toupper,
    values_to = "score"
  ) |>
  group_by(learner_id, measure) |>
  summarize(
    mean = mean(score, na.rm = TRUE),
    median = median(score, na.rm = TRUE),
    sd = sd(score, na.rm = TRUE),
    q25 = quantile(score, .25, na.rm = TRUE),
    q75 = quantile(score, .75, na.rm = TRUE),
    .groups = "drop"
  ) |>
  mutate(across(where(is.numeric), \(x) round(100 * x, 1))) |>
  mutate(
    mean = glue::glue("{mean} [{sd}]"),
    median = glue::glue("{median} [{q25}; {q75}]")
  ) |>
  select(-sd, -q25, -q75) |>
  tidyr::pivot_wider(names_from = measure, names_sep = "_", values_from = mean:median) |>
  select(learner_id, contains(toupper(c("rmse", "mae", "rrse")))) |>
  mutate(learner_id = learner_label(learner_id)) |>
  kbl(
    col.names = c("Learner", rep(c("Mean [SD]", "Median [q25; q75]"), 3)),
    booktabs = TRUE
  ) |>
  kable_styling(full_width = TRUE, latex_options = c("HOLD_position")) |>
  add_header_above(header = c(" " = 1, "RMSE" = 2, "MAE" = 2, "RRSE" = 2)) |>
  column_spec(1, "4cm")
  # column_spec(2, "2.3cm") |>
  # column_spec(3, "3cm") |>
  # column_spec(4, "2.3cm") |>
  # column_spec(5, "3cm")
```


### Results per Task

Tasks ordered by $n \cdot p$, decreasing.

```{r per-task}
#| fig-width: 16
#| fig-height: 11
#| fig-align: center
#| column: screen-inset-shaded

scores |>
  ggplot(aes(y = learner_id, x = rmse, fill = learner_id)) +
  facet_wrap(vars(task_label), ncol = 4, scales = "free") +
  geom_boxplot(alpha = .5) +
  geom_point() +
  scale_fill_manual(values = learner_cols, guide = "none") +
  scale_x_continuous(labels = scales::label_comma()) +
  scale_y_discrete(labels = learner_label) +
  labs(
    # title = "Scores per task",
    # subtitle = "Tasks ordered by n * p, decreasing",
    y = NULL, x = "RMSE"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    panel.spacing.x = unit(1, "cm"),
    plot.title.position = "plot"
  )

```

Without featureless learner

```{r per-task-no-featless}
#| fig-width: 12
#| fig-height: 9
#| fig-align: center
#| column: screen-inset-shaded

scores |>
  filter(learner_id != "featureless") |>
  ggplot(aes(y = learner_id, x = rmse, fill = learner_id)) +
  facet_wrap(vars(task_label), ncol = 4, scales = "free") +
  geom_boxplot(alpha = .5) +
  geom_point() +
  scale_fill_manual(values = learner_cols, guide = "none") +
  scale_x_continuous(labels = scales::label_comma()) +
  scale_y_discrete(labels = learner_label) +
  labs(
    # title = "Scores per task",
    # subtitle = "Tasks ordered by n * p, decreasing",
    y = NULL, x = "RMSE"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    panel.spacing.x = unit(1, "cm"),
    plot.title.position = "plot"
  )

```


### Tuning Results

Showing best performing parameter combinations of the inner folds, e.g. the parameters that "won".
One plot per hyperparameter, with performance on y-axis.

Note that `max_interaction` is tuned by tuning `max_interaction_ratio` within [0, 1] and then calculating

$$\max(\lceil \mathtt{max\_interaction\_ratio} \cdot \min(p, 30)\rceil, 1)$$

to effectively tune `max_interaction` within 1 and $p$ or 30, whichever is lower. 
This is not ideal since multiple values for `max_interaction_ratio` could result in the same value for `max_interaction` for large $p$, but it's a compromise.

```{r tuning-results, eval = FALSE}
#| fig-width: 12
#| fig-height: 7
#| fig-align: center
#| column: screen-inset-shaded

tuning_results_rpf |>
  ggplot(aes(x = splits, y = regr.mse, color = learner_name)) +
  facet_wrap(vars(task_name)) +
  geom_point(size = 2, alpha = .75) +
  scale_color_brewer(palette = "Dark2") +
  labs(
    title = "Regression tuning results",
    subtitle = "Tuned on MSE"
  ) +
  theme_minimal() +
  theme(
    panel.spacing.x = unit(1, "cm"),
    legend.position = "bottom"
  )


```
