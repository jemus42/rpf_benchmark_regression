---
title: "RPF Regression Benchmark Results"
author: "Lukas"
date: now
date-format: "YYYY-MM-DD HH:mm z"
date-modified: last-modified
lightbox: true
format: 
  html:
    code-fold: true
    fig-align: center
    toc: true
  pdf: 
    documentclass: article
    fig-align: center
    toc: true
    date: now
    keep-tex: true
    knitr: 
      opts_chunk: 
        echo: false
        fig.pos: H
    include-in-header: 
      - \usepackage{float}
editor_options: 
  chunk_output_type: console
---

```{r setup}
#| message: false
#| warning: false
library(ggplot2)
library(ragg)
library(mlr3)
#library(mlr3batchmark)
#library(mlr3viz)
#library(mlr3tuning)
library(data.table)
library(dplyr)
library(kableExtra)

# Load task metadata
task_meta <- readRDS("task_meta.rds")

task_meta <- task_meta |>
  arrange(dim_rank) |>
  mutate(
    task_label = glue::glue("{task_id} ({n} x {p})"),
    task_label = factor(task_label, levels = task_label, ordered = TRUE),
    task_id = factor(task_id, levels = task_id, ordered = TRUE)
  )

# benchmark results
aggr   <- readRDS(fs::path(conf$result_path, "aggr",   ext = "rds"))
scores <- readRDS(fs::path(conf$result_path, "scores", ext = "rds"))
scores <- task_meta[scores, on = c("task_id")]

archives_rpf <- readRDS(fs::path(conf$result_path, "archives_rpf", ext = "rds"))
results_rpf <- readRDS(fs::path(conf$result_path, "results_rpf", ext = "rds"))

# Define learner colors for somewhat identifiable plots
learner_cols <- c(
  "rpf" = "#F73098",
  "xgb" = "#3BA99C",
  "rpf_fixdepth" = "#CA1694",
  "xgb_fixdepth" = "#256A62",
  "ranger" = "#2171B5",
  "featureless" = "#484848"
)
learner_order <- names(learner_cols)
learner_label <- function(x) {
  x <- as.character(x)
  ret <- c("rpf" = "RPF", "xgb" = "XGBoost", "rpf_fixdepth" = "RPF (2)", "xgb_fixdepth" = "XGBoost (2)", "ranger" = "ranger", "featureless" = "Featureless")[x]
  unname(ret)
}

# aggr[, learner_label := learner_label(learner_id)]
# scores[, learner_label := learner_label(learner_id)]
aggr[, learner_id := factor(learner_id, levels = rev(learner_order))]
scores[, learner_id := factor(learner_id, levels = rev(learner_order))]

set.seed(3) # Only for jitterdodge consistency
```

## Benchmark Setup

- Inner resampling: 2x3-fold repeated CV
- Outer resampling: 10-fold CV using the same resampling folds as [the CTR-23 paper](https://openreview.net/pdf?id=HebAOoMm94). Some tasks use multiple repetitions.
- Bayesian optimization with 200 evaluations
- A runtime limit of 7 days for each outer resampling fold (including tuning)

### Hyperparameter Search Spaces

### RPF / RPF (2)

- `ntrees` := 50
- `max_interaction` in [1, 20]
    - Via `max_interaction_ratio` in [0, 1] and `max_interaction_limit` := 20
    - for **RPF (2)**: `max_interaction` := 2
- `splits` in [10, 100]
- `splits_try` in [1, 20]
- `t_try` in [0.1, 1]

### ranger

- `num.trees` := 500
- `mtry.ratio` in [0.1, 1]
- `min.node.size` in [1, 50]
- `sample.fracton` in [0.1, 1]

### XGBoost / XGBoost (2)

- Preprocessing of categorical features using treatment encoding
- `max_depth` in [1, 20]
    - for **XGBoost (2)**: `max_depth` := 2
- `subsample` in [0.1, 1]
- `colsample_bytree` in [0.1, 1]
- `eta` in [0.0001, 1] (log scale)
- `nrounds` in [10, 5000]

### Tasks

[OpenML CTR-23](https://www.openml.org/search?type=study&study_type=task&sort=tasks_included&id=353) tasks with:

- No missing values
- $n \cdot p \leq 10^6$
- No features of type `logical` or `character`

```{r tasks}
task_meta |>
  select(task_id, n, p, dim) |>
  arrange(dim) |>
  kbl(
    caption = "Selected OpenML CTR-23 tasks, arranged by dimensionality",
    col.names = c("Task", "n", "p", "nÂ·p"),
    booktabs = TRUE
  ) |>
  kable_styling()
```

## Regression Benchmark Results

- Tuning on Mean Squared Error (MSE)
- Evaluation on 
  - Root Mean Square Error (RMSE)
  - Root Relative Squared Error ([RRSE](https://mlr3measures.mlr-org.com/reference/rrse.html)), where 1 corresponds to the performance of the featureless learner and lower is better
  - Median Absolute Error (MAE)

### Aggregated Results

```{r}
plot_aggr <- function(xdf, 
                      measures = c("rmse", "mae", "rrse"),
                      include_featless = TRUE, logscale = FALSE, ncol = 2, outlier_threshold = 1e4) {
  
  xdf <- xdf |>
    tidyr::pivot_longer(
      cols = any_of(measures),
      names_to = "measure",
      values_to = "score"
    ) |>
    mutate(
      measure = factor(measure, levels = c("rmse", "rrse", "mae"))
    )

  if (!include_featless) {
    xdf <- xdf |>
      filter(learner_id != "featureless")
  }
  
  if (!logscale) {
    num_outliers <- sum(xdf$score > outlier_threshold)
    xdf <- xdf |>
      filter(score < .env$outlier_threshold)
  }

  p <- xdf |>
    filter(.data$measure %in% .env$measures) |>
    ggplot(aes(y = learner_id, x = score, fill = learner_id)) +
    facet_wrap(vars(measure), ncol = ncol, scales = "free", labeller = \(x) lapply(x, toupper)) +
    geom_boxplot(alpha = .5) +
    geom_point(
      position = position_jitterdodge(dodge.width = .25),
      shape = 21
    ) +
    scale_y_discrete(labels = learner_label) +
    scale_fill_manual(values = learner_cols, guide = "none") +
    labs(
      #title = "Aggregated scores over all tasks",
      x = NULL, y = NULL
    ) +
    theme_minimal(base_size = 14) +
    theme(
      plot.title.position = "plot"
    )
  
  if (logscale) {
    p <- p + scale_x_log10(labels = scales::label_comma(accuracy = 0.01)) +
      labs(x = "Scores (log10)")
  } else {
    p <- p + scale_x_continuous(labels = scales::label_comma()) +
      labs(x = "Scores", caption = glue::glue("{num_outliers} outlier scores above {outlier_threshold} are omitted"))
  }
  p
}
```


#### Boxplot

::: {.panel-tabset}

##### Regular

```{r aggregated}
#| fig-width: 12
#| fig-height: 7
#| fig-align: center
#| column: screen-inset-shaded

plot_aggr(aggr, include_featless = TRUE, logscale = FALSE, ncol = 1)
```

Without featureless learner

```{r aggregated-no-featless}
#| fig-width: 12
#| fig-height: 7
#| fig-align: center
#| column: screen-inset-shaded

plot_aggr(aggr, include_featless = FALSE, logscale = FALSE, ncol = 1)
```

##### Log Scale

```{r aggregated-logscale}
#| fig-width: 12
#| fig-height: 7
#| fig-align: center
#| column: screen-inset-shaded

plot_aggr(aggr, include_featless = TRUE, logscale = TRUE, ncol = 1)
```

Without featureless learner

```{r aggregated-logscale-no-featless}
#| fig-width: 12
#| fig-height: 7
#| fig-align: center
#| column: screen-inset-shaded

plot_aggr(aggr, include_featless = FALSE, logscale = TRUE, ncol = 1)
```


:::

#### Table

```{r aggregated-table}
# column: screen-inset-shaded
aggr |>
  tidyr::pivot_longer(
    cols = any_of(c("rmse", "mae", "rrse")),
    names_to = "measure", names_transform = toupper,
    values_to = "score"
  ) |>
  group_by(learner_id, measure) |>
  summarize(
    mean = mean(score, na.rm = TRUE),
    median = median(score, na.rm = TRUE),
    sd = sd(score, na.rm = TRUE),
    q25 = quantile(score, .25, na.rm = TRUE),
    q75 = quantile(score, .75, na.rm = TRUE),
    .groups = "drop"
  ) |>
  mutate(across(where(is.numeric), \(x) round(x, 2))) |>
  mutate(
    mean = glue::glue("{mean} [{sd}]"),
    median = glue::glue("{median} [{q25}; {q75}]")
  ) |>
  select(-sd, -q25, -q75) |>
  tidyr::pivot_wider(names_from = measure, names_sep = "_", values_from = mean:median) |>
  select(learner_id, contains(toupper(c("rmse", "mae", "rrse")))) |>
  mutate(learner_id = learner_label(learner_id)) |>
  kbl(
    col.names = c("Learner", rep(c("Mean [SD]", "Median [q25; q75]"), 3)),
    booktabs = TRUE
  ) |>
  kable_styling(full_width = TRUE, latex_options = c("HOLD_position")) |>
  add_header_above(header = c(" " = 1, "RMSE" = 2, "MAE" = 2, "RRSE" = 2)) |>
  column_spec(1, "4cm")
  # column_spec(2, "2.3cm") |>
  # column_spec(3, "3cm") |>
  # column_spec(4, "2.3cm") |>
  # column_spec(5, "3cm")
```


### Results per Task

```{r}
plot_scores <- function(xdf, measure = "rmse", include_featless = TRUE, logscale = FALSE, ncol = 4) {
  xdf <- xdf |>
    tidyr::pivot_longer(
      cols = any_of(c("rmse", "mae", "rrse")),
      names_to = "measure", names_transform = toupper,
      values_to = "score"
    ) |>
    filter(.data$measure == toupper(.env$measure))
  
  if (!include_featless) {
    xdf <- xdf |>
      filter(learner_id != "featureless")
  }
  
  p <- xdf |>
    ggplot(aes(y = learner_id, x = score, fill = learner_id)) +
    facet_wrap(vars(task_label), ncol = ncol, scales = "free") +
    geom_boxplot(alpha = .5) +
    geom_point() +
    scale_fill_manual(values = learner_cols, guide = "none") +
    scale_y_discrete(labels = learner_label) +
    labs(
      # title = "Scores per task",
      # subtitle = "Tasks ordered by n * p, decreasing",
      y = NULL, x = toupper(measure)
    ) +
    theme_minimal(base_size = 13) +
    theme(
      panel.spacing.x = unit(1, "cm"),
      plot.title.position = "plot"
    )
  
  if (logscale) {
    p + scale_x_log10(labels = scales::label_comma(accuracy = 0.01))
  } else {
    p + scale_x_continuous(labels = scales::label_comma())
  }
}
```

Tasks ordered by $n \cdot p$, decreasing.

::: {.panel-tabset}

#### RMSE

```{r per-task-rmse}
#| fig-width: 16
#| fig-height: 11
#| fig-align: center
#| column: screen-inset-shaded
#| message: false
#| error: false

plot_scores(scores, "rmse", include_featless = TRUE, logscale = FALSE, ncol = 4)
```

Without featureless learner

```{r per-task-rmse-no-featless}
#| fig-width: 16
#| fig-height: 11
#| fig-align: center
#| column: screen-inset-shaded
#| message: false
#| error: false

plot_scores(scores, "rmse", include_featless = FALSE, logscale = FALSE, ncol = 4)
```

#### MAE

```{r per-task-mae}
#| fig-width: 16
#| fig-height: 11
#| fig-align: center
#| column: screen-inset-shaded
#| message: false
#| error: false

plot_scores(scores, "mae", include_featless = TRUE, logscale = FALSE, ncol = 4)
```

Without featureless learner

```{r per-task-mae-no-featless}
#| fig-width: 16
#| fig-height: 11
#| fig-align: center
#| column: screen-inset-shaded
#| message: false
#| error: false

plot_scores(scores, "mae", include_featless = FALSE, logscale = FALSE, ncol = 4)
```

#### RRSE

```{r per-task-rrse}
#| fig-width: 16
#| fig-height: 11
#| fig-align: center
#| column: screen-inset-shaded
#| message: false
#| error: false

plot_scores(scores, "rrse", include_featless = TRUE, logscale = FALSE, ncol = 4)
```

Without featureless learner

```{r per-task-rrse-no-featless}
#| fig-width: 16
#| fig-height: 11
#| fig-align: center
#| column: screen-inset-shaded
#| message: false
#| error: false

plot_scores(scores, "rrse", include_featless = FALSE, logscale = FALSE, ncol = 4)
```

:::

### Tuning Results

```{r}
plot_archive <- function(xdf, param) {
  xdf |>
    ggplot(aes(x = .data[[param]], y = rmse, color = learner_id, fill = learner_id)) +
    facet_wrap(vars(task_label), scales = "free") +
    geom_point(size = 2, alpha = .1, shape = 21, key_glyph = "rect") +
    geom_smooth(se = FALSE, show.legend = FALSE) +
    scale_color_brewer(palette = "Dark2", labels = learner_label, aesthetics = c("color", "fill")) +
    scale_y_continuous(labels = scales::label_comma()) +
    guides(fill = guide_legend(override.aes = list(alpha = .8))) +
    labs(
      title = glue::glue("RPF tuning archives for param `{param}`"),
      subtitle = "Result of up to 200 evaluations of Bayesian optimization",
      y = "RMSE", color = NULL, fill = NULL
    ) +
    theme_minimal() +
    theme(
      panel.spacing.x = unit(5, "mm"),
      legend.position = "top",
      plot.title.position = "plot"
    )
}
```


Showing only the best performing parameter combinations of the inner folds, e.g. the parameters that "won".
One plot per hyperparameter, with performance on y-axis.

Note that `max_interaction` is tuned by tuning `max_interaction_ratio` within [0, 1] and then calculating

$$\max(\lceil \mathtt{max\_interaction\_ratio} \cdot \min(p, 20)\rceil, 1)$$

to effectively tune `max_interaction` within 1 and $p$ or 20, whichever is lower. 
This is not ideal since multiple values for `max_interaction_ratio` could result in the same value for `max_interaction` for small $p$, but it's a compromise.

```{r tuning-results}
#| fig-width: 12
#| fig-height: 7
#| fig-align: center
#| column: screen-inset-shaded
#| message: false
#| error: false
#| warning: false

plot_archive(results_rpf, "splits")
plot_archive(results_rpf, "split_try")
plot_archive(results_rpf, "t_try")
plot_archive(results_rpf, "max_interaction")
```

### Tuning Archives

Showing all evaluated hyperparameter configurations to get an impression of the space the MBO algorithm explored.

```{r tuning-archives}
#| fig-width: 12
#| fig-height: 7
#| fig-align: center
#| column: screen-inset-shaded
#| message: false
#| error: false
#| warning: false

plot_archive(archives_rpf, "splits")
plot_archive(archives_rpf, "split_try")
plot_archive(archives_rpf, "t_try")
plot_archive(archives_rpf, "max_interaction")
```

